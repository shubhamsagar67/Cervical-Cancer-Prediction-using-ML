{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7026,"status":"ok","timestamp":1702099513682,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"67ca2924","outputId":"85806ba7-3c31-4802-bbe8-216bedfe6463"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.9.26)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.5.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n"]}],"source":["!pip install opencv-python numpy scikit-image"],"id":"67ca2924"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7623,"status":"ok","timestamp":1702099521302,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"fc80e198","outputId":"601d7228-3594-4252-b150-9796623c67c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n","Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n","Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n","Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"]}],"source":["!pip install tensorflow"],"id":"fc80e198"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9061,"status":"ok","timestamp":1702198584126,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"bc43cba5","outputId":"dc88466f-74fb-4391-cd7f-266fafc5d4d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mahotas\n","  Downloading mahotas-1.4.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mahotas) (1.23.5)\n","Installing collected packages: mahotas\n","Successfully installed mahotas-1.4.13\n"]}],"source":["pip install mahotas"],"id":"bc43cba5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0e8b134"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","#%matplotlib inline\n","import os\n","import cv2\n","from tensorflow import keras\n","import tensorflow as tf\n","#import keras\n","# example of converting an image with the Keras API\n","from keras.preprocessing.image import ImageDataGenerator\n","# from keras.preprocessing.image import image_utils\n","from skimage.feature import graycomatrix, graycoprops\n","from keras.utils import load_img, img_to_array\n","from PIL import Image\n","#from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n","from keras.models import Model\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten,MaxPool2D\n","# from tensorflow.keras import layers, models\n","from keras.utils import to_categorical\n","from keras import layers, models\n","from sklearn.metrics import confusion_matrix , classification_report\n","import pickle\n","from skimage.feature import greycomatrix, graycoprops, local_binary_pattern, hog\n","import mahotas.features.texture as mhtex"],"id":"c0e8b134"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39834,"status":"ok","timestamp":1702198628591,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"WDSMKGMyxGcL","outputId":"438803ae-5dcb-484d-f874-533af6172931"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"WDSMKGMyxGcL"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f8b0c989"},"outputs":[],"source":["# Main Dataset Loading Process\n","#training path\n","TRAIN_PATH = '/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/train/'\n","# testing path\n","TEST_PATH = '/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/test/'"],"id":"f8b0c989"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4af60e59"},"outputs":[],"source":["# Creating a directory to save the filtered images\n","output_dir_train = '/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Filter_train'\n","output_dir_test = '/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Filter_test'\n","\n","os.makedirs(output_dir_train, exist_ok=True)\n","os.makedirs(output_dir_test, exist_ok=True)"],"id":"4af60e59"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6a77e0df"},"outputs":[],"source":["# divinding it in classes\n","classes = { 0:\"carcinoma_in_situ\", 1:\"light_dysplastic\", 2:\"moderate_dysplastic\",3:\"normal_columnar\",\n","            4:\"normal_intermediate\",5:\"normal_superficiel\",6:\"severe_dysplastic\"}"],"id":"6a77e0df"},{"cell_type":"code","execution_count":null,"metadata":{"id":"29ac8ca8"},"outputs":[],"source":["for cl in classes:\n","  path = os.path.join(output_dir_train, classes[cl])\n","  os.makedirs(path, exist_ok=True)\n","\n","for cl in classes:\n","  path = os.path.join(output_dir_test, classes[cl])\n","  os.makedirs(path, exist_ok=True)"],"id":"29ac8ca8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"61e4cb56"},"outputs":[],"source":["# List all image files in the dataset directory\n","image_files_train = [os.path.join(TRAIN_PATH, filename) for filename in os.listdir(TRAIN_PATH) if filename.lower().endswith('.BMP')]\n","image_files_test = [os.path.join(TEST_PATH, filename) for filename in os.listdir(TEST_PATH) if filename.lower().endswith('.BMP')]"],"id":"61e4cb56"},{"cell_type":"markdown","metadata":{"id":"n4FvOVal-a_0"},"source":["# NLM Filter"],"id":"n4FvOVal-a_0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"10221d30"},"outputs":[],"source":["# Defination of NLM filter function\n","def nlm_filter(image):\n","    filtered_image = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)  # Adjust parameters as needed\n","    return filtered_image"],"id":"10221d30"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309221,"status":"ok","timestamp":1702100537648,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"04311535","outputId":"f45523a6-4a19-4776-ca9c-78c44bfe095e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Noise removal and PNG conversion completed for train images.\n","Noise removal and PNG conversion completed for test images.\n"]}],"source":["# Applying NLM filtering to each image, converting to PNG, and saving the filtered images\n","\n","# Train Images\n","for cl in classes:\n","    pth = TRAIN_PATH + classes[cl]\n","    for image_filename in os.listdir(pth):\n","        # Load the image using OpenCV\n","        image = cv2.imread(pth + '/' + image_filename)\n","\n","        # Convert the image to RGB (OpenCV reads images in BGR format)\n","        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        # Apply NLM filtering\n","        filtered_image = nlm_filter(image_rgb)\n","\n","        # Get the file name without extension\n","        filename = os.path.splitext(os.path.basename(image_filename))[0]\n","\n","        # Save the filtered image as PNG format\n","        output_file = os.path.join(output_dir_train + '/' + classes[cl], f'{filename}_nlmfiltered.png')\n","        cv2.imwrite(output_file, filtered_image)\n","\n","print(\"Noise removal and PNG conversion completed for train images.\")\n","\n","\n","# Test Images\n","for cl in classes:\n","    pth = TEST_PATH + classes[cl]\n","    for image_filename in os.listdir(pth):\n","        # Load the image using OpenCV\n","        image = cv2.imread(pth + '/' + image_filename)\n","\n","        # Convert the image to RGB (OpenCV reads images in BGR format)\n","        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        # Apply NLM filtering\n","        filtered_image = nlm_filter(image_rgb)\n","\n","        # Get the file name without extension\n","        filename = os.path.splitext(os.path.basename(image_filename))[0]\n","\n","        # Save the filtered image as PNG format\n","        output_file = os.path.join(output_dir_test + '/' + classes[cl], f'{filename}_nlmfiltered.png')\n","        cv2.imwrite(output_file, filtered_image)\n","\n","print(\"Noise removal and PNG conversion completed for test images.\")\n"],"id":"04311535"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":436,"status":"ok","timestamp":1702101198972,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"dea201c3","outputId":"6011b57b-ba90-42b4-c047-5145d84bbfa6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train classes:\n","normal_superficiel\n","carcinoma_in_situ\n","light_dysplastic\n","moderate_dysplastic\n","normal_intermediate\n","normal_columnar\n","severe_dysplastic\n","******************\n","Test classes:\n","severe_dysplastic\n","normal_superficiel\n","moderate_dysplastic\n","carcinoma_in_situ\n","normal_columnar\n","normal_intermediate\n","light_dysplastic\n"]}],"source":["# List all image files in the output directory\n","filtered_files_train = os.listdir(output_dir_train)\n","filtered_files_test = os.listdir(output_dir_test)\n","\n","# Printing the filtered image filenames for train\n","print(\"Train classes:\")\n","for file_name_train in filtered_files_train:\n","    print(file_name_train)\n","print(\"******************\")\n","print(\"Test classes:\")\n","# Printing the filtered image filenames for test\n","for file_name_test in filtered_files_test:\n","    print(file_name_test)"],"id":"dea201c3"},{"cell_type":"markdown","metadata":{"id":"9f0cde43"},"source":["# Augmentation"],"id":"9f0cde43"},{"cell_type":"code","execution_count":null,"metadata":{"id":"51b6be05"},"outputs":[],"source":["# Train Folder for Augmentation\n","input_folder_train = '/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Filter_train'\n","output_folder_train = '/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Augmentation/Train'\n","\n","for cl in classes:\n","  path = os.path.join(output_folder_train, classes[cl])\n","  os.makedirs(path, exist_ok=True)\n","\n","\n","#Create an ImageDataGenerator and specify the augmentation parameters\n","datagen = ImageDataGenerator(\n","    rotation_range=45,      # Rotate the image between -45 to 45 degrees\n","    width_shift_range=0.2,  # Shift the width of the image by up to 20%\n","    height_shift_range=0.2, # Shift the height of the image by up to 20%\n","    shear_range=0.2,        # Apply shear transformation with a shear factor of 0.2\n","    zoom_range=0.2,         # Zoom the image by up to 20%\n","    horizontal_flip=True,   # Flip the image horizontally\n","    vertical_flip=True     # Flip the image vertically\n","    # Add more augmentation parameters here\n",")"],"id":"51b6be05"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":561452,"status":"ok","timestamp":1702102118118,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"b82787ae","outputId":"c8cc5192-7fed-4505-f014-719bde2ce50b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Augmented images done for training set\n"]}],"source":["# Generate augmented images and save them to the output folder of train folder.\n","for cl in classes:\n","  pth = input_folder_train + '/' + classes[cl]\n","  for filename in os.listdir(pth):\n","    # Load the image using OpenCV\n","    image_path = cv2.imread(pth + '/' + filename)\n","\n","    # Convert the image to a NumPy array\n","    image_array = img_to_array(image_path)\n","\n","    # Reshape the image array to match the expected input shape of the generator\n","    image_array = image_array.reshape((1,) + image_array.shape)\n","\n","    # Generate augmented images using the datagen.flow() method\n","    augmented_images = datagen.flow(\n","          image_array,\n","          batch_size=1,\n","          save_to_dir= os.path.join(output_folder_train + '/' + classes[cl]), # Save the augmented images to the output folder\n","          save_prefix='augmented',    # Prefix to use for the saved images\n","          save_format='png'           # Save images in PNG format\n","      )\n","\n","    # Generate and save the augmented images\n","    num_augmented_images = 5  # Specify the number of augmented images to generate\n","    for i, augmented_image in enumerate(augmented_images):\n","        if i >= num_augmented_images:\n","            break\n","\n","        # Convert the augmented image to PIL format\n","        augmented_image_pil = Image.fromarray(augmented_image[0].astype('uint8'))\n","\n","        # Save the augmented image as PNG\n","        save_filename = f'{filename.split(\".\")[0]}_{i}.png'\n","        save_path = os.path.join(output_folder_train + '/' + classes[cl], save_filename)\n","        augmented_image_pil.save(save_path)\n","print(\"Augmented images done for training set\")"],"id":"b82787ae"},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJgYKG55feSP"},"outputs":[],"source":["# Test Folder for Augmentation\n","input_folder_test = '/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Filter_test'\n","output_folder_test = '/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Augmentation/Test'\n","\n","for cl in classes:\n","  path = os.path.join(output_folder_test, classes[cl])\n","  os.makedirs(path, exist_ok=True)"],"id":"qJgYKG55feSP"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227606,"status":"ok","timestamp":1702102345723,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"bcbfe5e0","outputId":"ae63148f-e222-4ca1-d19d-c06dfd6a6115"},"outputs":[{"name":"stdout","output_type":"stream","text":["Augmented images done for testing set\n"]}],"source":["# Generated augmented images and save them to the output folder of test folder.\n","for cl in classes:\n","  pth = input_folder_test + '/' + classes[cl]\n","  for filename in os.listdir(pth):\n","    # Load the image using OpenCV\n","    image_path = cv2.imread(pth + '/' + filename)\n","\n","    # Convert the image to a NumPy array\n","    image_array = img_to_array(image_path)\n","\n","    # Reshape the image array to match the expected input shape of the generator\n","    image_array = image_array.reshape((1,) + image_array.shape)\n","\n","    # Generate augmented images using the datagen.flow() method\n","    augmented_images = datagen.flow(\n","          image_array,\n","          batch_size=1,\n","          save_to_dir= os.path.join(output_folder_test + '/' + classes[cl]), # Save the augmented images to the output folder\n","          save_prefix='augmented',    # Prefix to use for the saved images\n","          save_format='png'           # Save images in PNG format\n","      )\n","\n","    # Generate and save the augmented images\n","    num_augmented_images = 5  # Specify the number of augmented images to generate\n","    for i, augmented_image in enumerate(augmented_images):\n","        if i >= num_augmented_images:\n","            break\n","\n","        # Convert the augmented image to PIL format\n","        augmented_image_pil = Image.fromarray(augmented_image[0].astype('uint8'))\n","\n","        # Save the augmented image as PNG\n","        save_filename = f'{filename.split(\".\")[0]}_{i}.png'\n","        save_path = os.path.join(output_folder_test + '/' + classes[cl], save_filename)\n","        augmented_image_pil.save(save_path)\n","print(\"Augmented images done for testing set\")"],"id":"bcbfe5e0"},{"cell_type":"markdown","metadata":{"id":"daef235c"},"source":["# Watershed Segmentation"],"id":"daef235c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"78904357"},"outputs":[],"source":["def segment_cell(image_path):\n","    # Reading the images\n","    image = cv2.imread(image_path)\n","\n","    # Converting the images to grayscale\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # Perform adaptive thresholding to obtain a binary image\n","    _, threshold = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","\n","    # Perform morphological operations to remove noise and fill gaps\n","    kernel = np.ones((3, 3), np.uint8)\n","    opening = cv2.morphologyEx(threshold, cv2.MORPH_OPEN, kernel, iterations=2)\n","\n","    # Find the sure background region\n","    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n","\n","    # Find the sure foreground region\n","    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n","    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n","\n","    # Finding the unknown region\n","    sure_fg = np.uint8(sure_fg)\n","    unknown = cv2.subtract(sure_bg, sure_fg)\n","\n","    # Creating a marker image\n","    _, markers = cv2.connectedComponents(sure_fg)\n","    markers = markers + 1\n","    markers[unknown == 255] = 0\n","\n","    # Applying the watershed algorithm\n","    markers = cv2.watershed(image, markers)\n","\n","    # Applying Color the segmented cells\n","    image[markers == -1] = [0, 0, 255]  # Mark boundaries with red color\n","\n","    return image"],"id":"78904357"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e54b10b2"},"outputs":[],"source":["# train folder\n","watershed_train = 'Herlev dataset/Watershed/Trainnn'\n","# test folder\n","watershed_test = 'Herlev dataset/Watershed/Testtt'\n","\n","for cl in classes:\n","  path_train = os.path.join(watershed_train, classes[cl])\n","  path_test = os.path.join(watershed_test, classes[cl])\n","  os.makedirs(path_train, exist_ok=True)\n","  os.makedirs(path_test, exist_ok=True)"],"id":"e54b10b2"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1046092,"status":"ok","timestamp":1702103425994,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"402f0399","outputId":"cf3772d3-e700-42bb-af4d-a212e4b616cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Segmented test images saved successfully as png\n"]}],"source":["import os\n","\n","for cl in classes:\n","    # Provide the path to the folder containing the input images\n","    folder_path = os.path.join('/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Augmentation/Train', classes[cl])\n","    watershed_testclass = os.path.join('/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Watershed/Trainnn', classes[cl])\n","\n","    # Create subfolders if they don't exist\n","    if not os.path.exists(watershed_testclass):\n","        os.makedirs(watershed_testclass)\n","\n","    # Get a list of all image files in the folder\n","    image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n","\n","    # Process each image in the folder\n","    for image_file in image_files:\n","        # Construct the full path to the image\n","        image_path = os.path.join(folder_path, image_file)\n","\n","        # Perform image segmentation\n","        segmented_image = segment_cell(image_path)\n","\n","        # Save the segmented image with the same filename and PNG extension in the subfolder\n","        output_path = os.path.join(watershed_testclass, image_file)  # Use the same filename\n","        cv2.imwrite(output_path, segmented_image)\n","\n","print(\"Segmented test images saved successfully as png\")\n"],"id":"402f0399"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"d43b50de","outputId":"a4f5cdf0-0b92-4e0e-9694-1e9c3bdf9f7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Segmented test images saved successfully as png\n"]}],"source":["import os\n","\n","for cl in classes:\n","    # Provide the path to the folder containing the input images\n","    folder_path = os.path.join('/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Augmentation/Test', classes[cl])\n","    watershed_testclass = os.path.join('/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Watershed/Testtt', classes[cl])\n","\n","    # Create subfolders if they don't exist\n","    if not os.path.exists(watershed_testclass):\n","        os.makedirs(watershed_testclass)\n","\n","    # Get a list of all image files in the folder\n","    image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n","\n","    # Process each image in the folder\n","    for image_file in image_files:\n","        # Construct the full path to the image\n","        image_path = os.path.join(folder_path, image_file)\n","\n","        # Perform image segmentation\n","        segmented_image = segment_cell(image_path)\n","\n","        # Save the segmented image with the same filename and PNG extension in the subfolder\n","        output_path = os.path.join(watershed_testclass, image_file)  # Use the same filename\n","        cv2.imwrite(output_path, segmented_image)\n","\n","print(\"Segmented test images saved successfully as png\")\n"],"id":"d43b50de"},{"cell_type":"markdown","metadata":{"id":"8095d178"},"source":["# GLCM for Feature Extraction"],"id":"8095d178"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1GN8NEfGBA9Ao47R6epG1s9_05tfF_-fg"},"executionInfo":{"elapsed":72107,"status":"ok","timestamp":1702182846717,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"473e9941","outputId":"cfe10aea-ec1a-4a46-abfe-51c6d9033f51"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# GLCM for Training Images\n","for cl in classes:\n","  folder_path = os.path.join('/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Watershed/Trainnn', classes[cl])\n","\n","  for filename in os.listdir(folder_path):\n","    if filename.endswith('.png'):\n","        image_path = os.path.join(folder_path, filename)\n","        image = cv2.imread(image_path, 0)  # Read the image in grayscale\n","\n","        distances = [1]\n","        angles = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]\n","\n","        glcm = graycomatrix(image, distances, angles, levels=256, symmetric=True, normed=True)\n","\n","        properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n","        features = np.ravel([graycoprops(glcm, prop).reshape(-1) for prop in properties])\n","\n","        # Additional properties using mahotas\n","        haralick_features = mhtex.haralick(image)\n","        asm = haralick_features[:, 0].mean()\n","        cluster_prominence = haralick_features[:, 3].mean()\n","        cluster_shade = haralick_features[:, 4].mean()\n","        max_prob = haralick_features[:, 8].mean()\n","\n","        # Additional features using skimage\n","        radius = 3\n","        n_points = 8 * radius\n","        lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n","        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n","        lbp_hist = lbp_hist.astype(np.float)\n","        lbp_hist /= (lbp_hist.sum() + 1e-6)  # Normalize LBP histogram\n","\n","        hog_features = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1))\n","\n","        print(f'Features for image: {filename}')\n","        for prop, feature in zip(properties + ['ASM', 'cluster_prominence', 'cluster_shade', 'max_prob'],\n","                                 features.tolist() + [asm, cluster_prominence, cluster_shade, max_prob]):\n","            print(f'{prop}: {feature}')\n","        print(f'LBP: {lbp_hist.tolist()}') #Local Binary Patterns\n","        print(f'HOG: {hog_features.tolist()}') #Histogram of Oriented Gradients\n","        print('------------------------------')"],"id":"473e9941"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1wyL8X_zkv_FGszfWW1sgkdm1y_AO1iqe"},"executionInfo":{"elapsed":132243,"status":"ok","timestamp":1702183835805,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"7767f9ee","outputId":"96c0a2d7-aa83-40a5-974a-dbd3927cab8b"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# GLCM for Testing Images\n","for cl in classes:\n","  folder_path = os.path.join('/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Watershed/Testtt', classes[cl])\n","\n","  for filename in os.listdir(folder_path):\n","    if filename.endswith('.png'):\n","        image_path = os.path.join(folder_path, filename)\n","        image = cv2.imread(image_path, 0)  # Read the image in grayscale\n","\n","        distances = [1]\n","        angles = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]\n","\n","        glcm = graycomatrix(image, distances, angles, levels=256, symmetric=True, normed=True)\n","\n","        properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n","        features = np.ravel([graycoprops(glcm, prop).reshape(-1) for prop in properties])\n","\n","        # Additional properties using mahotas\n","        haralick_features = mhtex.haralick(image)\n","        asm = haralick_features[:, 0].mean()\n","        cluster_prominence = haralick_features[:, 3].mean()\n","        cluster_shade = haralick_features[:, 4].mean()\n","        max_prob = haralick_features[:, 8].mean()\n","\n","        # Additional features using skimage\n","        radius = 3\n","        n_points = 8 * radius\n","        lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n","        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n","        lbp_hist = lbp_hist.astype(np.float)\n","        lbp_hist /= (lbp_hist.sum() + 1e-6)  # Normalize LBP histogram\n","\n","        hog_features = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1))\n","\n","        print(f'Features for image: {filename}')\n","        for prop, feature in zip(properties + ['ASM', 'cluster_prominence', 'cluster_shade', 'max_prob'],\n","                                 features.tolist() + [asm, cluster_prominence, cluster_shade, max_prob]):\n","            print(f'{prop}: {feature}')\n","        print(f'LBP: {lbp_hist.tolist()}')\n","        print(f'HOG: {hog_features.tolist()}')\n","        print('------------------------------')"],"id":"7767f9ee"},{"cell_type":"markdown","metadata":{"id":"466982cb"},"source":["# PCA"],"id":"466982cb"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Cibg1S5jGkFk4Gc-y65Vw2oZdDT6KH2F"},"id":"fc1b827e","outputId":"d1bdf2b6-eb27-4fb3-93ab-41f613fceef8"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# PCA for training\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","from matplotlib.pyplot import imread\n","\n","# Assuming 'classes' is a dictionary mapping class labels to folder names\n","\n","# Define the output folder for PCA-transformed images\n","output_folder = 'Herlev dataset/PCA_Transformed_Images/training'\n","os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n","\n","for cl in classes:\n","    # Define the path to the folder containing the images\n","    folder_path = os.path.join('/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Watershed/Trainnn', classes[cl])\n","\n","    # Process each image in the folder\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith('.png'):\n","            image_path = os.path.join(folder_path, filename)\n","            img = plt.imread(image_path).astype(np.float32) / 255.0  # Load and normalize image\n","\n","            # Convert RGB image to grayscale (assuming it's an RGB image)\n","            img = img.mean(axis=2)\n","\n","            plt.imshow(img, cmap=\"gray\")\n","            plt.title(\"Original Image\")\n","            plt.show()\n","\n","            def transform_image(percentage, output_filename):\n","                percentage = percentage / 100\n","                tswizzle_pca = PCA(n_components=percentage).fit(img)\n","                transformed = tswizzle_pca.transform(img)\n","                projection = tswizzle_pca.inverse_transform(transformed)\n","\n","                plt.imshow(projection, cmap=\"gray\")\n","                plt.title(f\"PCA Transformed Image (Percentage: {percentage * 100}%)\")\n","                plt.savefig(output_filename)  # Save the PCA-transformed image\n","                plt.show()\n","\n","            # Create the output filename for the PCA-transformed image\n","            output_filename = os.path.join(output_folder, f'{filename[:-4]}_pca.png')\n","\n","            transform_image(95, output_filename)  # Call the transform function with desired percentage\n"],"id":"fc1b827e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"90c9100e"},"outputs":[],"source":["# PCA for testing\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","\n","# Assuming 'classes' is a dictionary mapping class labels to folder names\n","\n","# Define the output folder for PCA-transformed images\n","output_folder = 'Herlev dataset/PCA_Transformed_Images/testing'\n","os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n","\n","for cl in classes:\n","    # Define the path to the folder containing the images\n","    folder_path = os.path.join('/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Watershed/Testtt', classes[cl])\n","\n","    # Process each image in the folder\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith('.png'):\n","            image_path = os.path.join(folder_path, filename)\n","            img = plt.imread(image_path).astype(np.float32) / 255.0  # Load and normalize image\n","\n","            # Convert RGB image to grayscale (assuming it's an RGB image)\n","            img = img.mean(axis=2)\n","\n","            plt.imshow(img, cmap=\"gray\")\n","            plt.title(\"Original Image\")\n","            plt.show()\n","\n","            def transform_image(percentage, output_filename):\n","                percentage = percentage / 100\n","                tswizzle_pca = PCA(n_components=percentage).fit(img)\n","                transformed = tswizzle_pca.transform(img)\n","                projection = tswizzle_pca.inverse_transform(transformed)\n","\n","                plt.imshow(projection, cmap=\"gray\")\n","                plt.title(f\"PCA Transformed Image (Percentage: {percentage * 100}%)\")\n","                plt.savefig(output_filename)  # Save the PCA-transformed image\n","                plt.show()\n","\n","            # Create the output filename for the PCA-transformed image\n","            output_filename = os.path.join(output_folder, f'{filename[:-4]}_pca.png')\n","\n","            transform_image(95, output_filename)  # Call the transform function with desired percentage\n"],"id":"90c9100e"},{"cell_type":"markdown","metadata":{"id":"6130904d"},"source":["# Classification (Random Forest)"],"id":"6130904d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5b7bfb32","outputId":"5811ae1f-c803-401e-f60a-7905527fedc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8888888888888888\n"]}],"source":["                                                                          # OLD CODE\n","# # classification for training data\n","# import os\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# from sklearn.decomposition import PCA\n","# from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.metrics import accuracy_score\n","\n","# # Assuming 'classes' is a dictionary mapping class labels to folder names\n","\n","# # Define the output folder for PCA-transformed images\n","# output_folder = 'PCA_Transformed_Images/training'\n","# os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n","\n","# X = []  # List to store PCA-transformed images as features\n","# y = []  # List to store corresponding class labels\n","\n","# for cl in classes:\n","#     # Define the path to the folder containing the images\n","#     folder_path = os.path.join('Herlev dataset/Watershed/Trainnn', classes[cl])\n","\n","#     # Process each image in the folder\n","#     for filename in os.listdir(folder_path):\n","#         if filename.endswith('.png'):\n","#             image_path = os.path.join(folder_path, filename)\n","#             img = plt.imread(image_path).astype(np.float32) / 255.0  # Load and normalize image\n","\n","#             # Convert RGB image to grayscale (assuming it's an RGB image)\n","#             img = img.mean(axis=2)\n","\n","#             # Apply PCA transformation\n","#             percentage = 89\n","#             tswizzle_pca = PCA(n_components=percentage / 100).fit(img)\n","#             transformed = tswizzle_pca.transform(img)\n","\n","#             flattened_transformed = transformed.ravel()\n","\n","#             # Check if the flattened_transformed has the expected length\n","#             expected_length = len(X[0]) if X else len(flattened_transformed)\n","#             if len(flattened_transformed) == expected_length:\n","#                 X.append(flattened_transformed)\n","#                 y.append(cl)  # Add class label\n","\n","# # Convert the lists to arrays for training\n","# X = np.array(X)\n","# y = np.array(y)\n","\n","# # Convert the lists to arrays for training\n","# X = np.array(X)\n","# y = np.array(y)\n","\n","# # Split data into training and testing sets\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# # Train a Random Forest classifier\n","# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","# rf_classifier.fit(X_train, y_train)\n","\n","# # Predict using the trained classifier\n","# y_pred = rf_classifier.predict(X_test)\n","\n","# # Evaluate the classifier\n","# accuracy = accuracy_score(y_test, y_pred)\n","# print(\"Accuracy:\", accuracy)\n"],"id":"5b7bfb32"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":265475,"status":"ok","timestamp":1702198927157,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"yaEV6maNy_ba","colab":{"base_uri":"https://localhost:8080/"},"outputId":"12ac5c97-7456-4a60-8938-2ab3e65dd73d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6\n"]}],"source":["                                                                        # LATEST CODE\n","\n","# classification for training data\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Assuming 'classes' is a dictionary mapping class labels to folder names\n","\n","# Define the output folder for PCA-transformed images\n","output_folder = 'PCA_Transformed_Images/training'\n","os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n","\n","X = []  # List to store PCA-transformed images as features\n","y = []  # List to store corresponding class labels\n","\n","for cl in classes:\n","    # Define the path to the folder containing the images\n","    folder_path = os.path.join('/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Watershed/Trainnn', classes[cl])\n","\n","    # Process each image in the folder\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith('.png'):\n","            image_path = os.path.join(folder_path, filename)\n","            img = plt.imread(image_path).astype(np.float32) / 255.0  # Load and normalize image\n","\n","            # Converting RGB image to grayscale\n","            img = img.mean(axis=2)\n","\n","            # Applying PCA transformation\n","            percentage = 89\n","            tswizzle_pca = PCA(n_components=percentage / 100).fit(img)\n","            transformed = tswizzle_pca.transform(img)\n","\n","            flattened_transformed = transformed.ravel()\n","\n","            # Checking if the flattened_transformed has the expected length\n","            expected_length = len(X[0]) if X else len(flattened_transformed)\n","            if len(flattened_transformed) == expected_length:\n","                X.append(flattened_transformed)\n","                y.append(cl)  # Add class label\n","\n","# Converting the lists to arrays for training\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Converting the lists to arrays for training\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Spliting data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Training a Random Forest classifier\n","rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_classifier.fit(X_train, y_train)\n","\n","# Predicting using the trained classifier\n","y_pred = rf_classifier.predict(X_test)\n","\n","# Evaluating the classifier\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"],"id":"yaEV6maNy_ba"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fb1bc5fb","outputId":"71bb2119-842e-42f5-ebdb-9a8cdcda2889"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 1.0\n"]}],"source":["                                                                          # OLD CODE\n","# # classification for testing data\n","# import os\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# from sklearn.decomposition import PCA\n","# from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.metrics import accuracy_score\n","\n","# # Assuming 'classes' is a dictionary mapping class labels to folder names\n","\n","# # Define the output folder for PCA-transformed images\n","# output_folder = 'PCA_Transformed_Images/testing'\n","# os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n","\n","# X = []  # List to store PCA-transformed images as features\n","# y = []  # List to store corresponding class labels\n","\n","# for cl in classes:\n","#     # Define the path to the folder containing the images\n","#     folder_path = os.path.join('Herlev dataset/Watershed/Testtt', classes[cl])\n","\n","#     # Process each image in the folder\n","#     for filename in os.listdir(folder_path):\n","#         if filename.endswith('.png'):\n","#             image_path = os.path.join(folder_path, filename)\n","#             img = plt.imread(image_path).astype(np.float32) / 255.0  # Load and normalize image\n","\n","#             # Convert RGB image to grayscale (assuming it's an RGB image)\n","#             img = img.mean(axis=2)\n","\n","#             # Apply PCA transformation\n","#             percentage = 89\n","#             tswizzle_pca = PCA(n_components=percentage / 100).fit(img)\n","#             transformed = tswizzle_pca.transform(img)\n","\n","#             flattened_transformed = transformed.ravel()\n","\n","#             # Check if the flattened_transformed has the expected length\n","#             expected_length = len(X[0]) if X else len(flattened_transformed)\n","#             if len(flattened_transformed) == expected_length:\n","#                 X.append(flattened_transformed)\n","#                 y.append(cl)  # Add class label\n","\n","# # Convert the lists to arrays for training\n","# X = np.array(X)\n","# y = np.array(y)\n","\n","# # Convert the lists to arrays for training\n","# X = np.array(X)\n","# y = np.array(y)\n","\n","# # Split data into training and testing sets\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# # Train a Random Forest classifier\n","# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","# rf_classifier.fit(X_train, y_train)\n","\n","# # Predict using the trained classifier\n","# y_pred = rf_classifier.predict(X_test)\n","\n","# # Evaluate the classifier\n","# accuracy = accuracy_score(y_test, y_pred)\n","# print(\"Accuracy:\", accuracy)\n"],"id":"fb1bc5fb"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":98803,"status":"ok","timestamp":1702199561527,"user":{"displayName":"Priyansh Soni","userId":"09666387813451142464"},"user_tz":-330},"id":"d3d3c2c5","outputId":"9623e917-aeae-4ffe-ddd5-72fd3cfad615"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.3333333333333333\n"]}],"source":["                                                                        # LATEST CODE\n","\n","# classification for testing data\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Assuming 'classes' is a dictionary mapping class labels to folder names\n","\n","# Define the output folder for PCA-transformed images\n","output_folder = 'PCA_Transformed_Images/testing'\n","os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n","\n","X = []  # List to store PCA-transformed images as features\n","y = []  # List to store corresponding class labels\n","\n","for cl in classes:\n","    # Define the path to the folder containing the images\n","    folder_path = os.path.join('/content/drive/MyDrive/NEW 7th Sem Project/Herlev dataset/Watershed/Testtt', classes[cl])\n","\n","    # Process each image in the folder\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith('.png'):\n","            image_path = os.path.join(folder_path, filename)\n","            img = plt.imread(image_path).astype(np.float32) / 255.0  # Load and normalize image\n","\n","            # Convert RGB image to grayscale (assuming it's an RGB image)\n","            img = img.mean(axis=2)\n","\n","            # Apply PCA transformation\n","            percentage = 89\n","            tswizzle_pca = PCA(n_components=percentage / 100).fit(img)\n","            transformed = tswizzle_pca.transform(img)\n","\n","            flattened_transformed = transformed.ravel()\n","\n","            # Check if the flattened_transformed has the expected length\n","            expected_length = len(X[0]) if X else len(flattened_transformed)\n","            if len(flattened_transformed) == expected_length:\n","                X.append(flattened_transformed)\n","                y.append(cl)  # Add class label\n","\n","# Convert the lists to arrays for training\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Convert the lists to arrays for training\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train a Random Forest classifier\n","rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_classifier.fit(X_train, y_train)\n","\n","# Predict using the trained classifier\n","y_pred = rf_classifier.predict(X_test)\n","\n","# Evaluate the classifier\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"],"id":"d3d3c2c5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"hD0KTiW36Dsf"},"outputs":[],"source":[],"id":"hD0KTiW36Dsf"}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}